{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sys import getsizeof # Get size of a variable in bytes\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Spacy\n",
    "import scispacy\n",
    "import spacy\n",
    "import en_core_sci_lg\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.matutils  import Sparse2Corpus\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_nicely(l): \n",
    "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
    "    \"\"\"Taken from: http://stackoverflow.com/questions/2669059/how-to-sort-alpha-numeric-set-in-python\"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)\n",
    "###END FUNCTION sorted_nicely(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read keywords (taken from external data sources) from csv files and store in dataframe<br>\n",
    "Files are obtained from 2.fulltext_external-keywords.ipynb.<br>\n",
    "They are stored as chunks of 500 documents each for ease of handling.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names\n",
    "files = glob.glob(f'keyword_match_data/*.csv', recursive=True)\n",
    "filelist = sorted_nicely(files)\n",
    "print(\"# of csv files read:\", len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from contents of all files.\n",
    "kw_df = pd.read_csv(filelist[0])\n",
    "for fname in filelist[1:]:\n",
    "    #print(fname)\n",
    "    kw_df = pd.concat([kw_df, pd.read_csv(fname)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>053bbe38ee5f3c97ade5b24a07b34b9930d3f474</td>\n",
       "      <td>['severe acute respiratory syndrome', 'glioma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>060f83d466d0f77513f8e3d2b55e149894211b64</td>\n",
       "      <td>['pseudomonas aeruginosa', 'human metapneumovi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce19f6664fc109d488b095746ef87195906df39d</td>\n",
       "      <td>['notch', 'nr', 'falls', 'hepatitis b', 'hepat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c83346b9e5e45cc987f59be4e9ad1e63c483ac9a</td>\n",
       "      <td>['dengue', 'water', 'vesicular stomatitis viru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af9d045b63744eb78fa9b2c1ad2a27169d9e0f01</td>\n",
       "      <td>['yellow fever', 'apoptosis', 'nr', 'atopic de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36452</th>\n",
       "      <td>1f55628e0dcd9b8f71cf130bbfc0baa1c4381900</td>\n",
       "      <td>['nr', 'apoptosis', 'tiletamine', 'arginine', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36453</th>\n",
       "      <td>5d2ed78357c0c88b4500d644f4a717d0192a0d2d</td>\n",
       "      <td>['water', 'hepatitis e', 'serine', 'aved', 'et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36454</th>\n",
       "      <td>e701970d6ca6c78bd19df6c7cb72224cdec7ee07</td>\n",
       "      <td>['water', 'ethanol', 'nr', 'pica', 'pain', 'bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36455</th>\n",
       "      <td>110f5cd40aa0ff4381f7abc3cabbc629f9794e66</td>\n",
       "      <td>['vaccinia', 'aved', 'ethylcellulose', 'pica',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36456</th>\n",
       "      <td>3dfe29d041cefc6bf7640ae82e2512dba55d9a7d</td>\n",
       "      <td>['water', 'aved', 'inositol', 'pica', 'parafor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paper_id  \\\n",
       "0      053bbe38ee5f3c97ade5b24a07b34b9930d3f474   \n",
       "1      060f83d466d0f77513f8e3d2b55e149894211b64   \n",
       "2      ce19f6664fc109d488b095746ef87195906df39d   \n",
       "3      c83346b9e5e45cc987f59be4e9ad1e63c483ac9a   \n",
       "4      af9d045b63744eb78fa9b2c1ad2a27169d9e0f01   \n",
       "...                                         ...   \n",
       "36452  1f55628e0dcd9b8f71cf130bbfc0baa1c4381900   \n",
       "36453  5d2ed78357c0c88b4500d644f4a717d0192a0d2d   \n",
       "36454  e701970d6ca6c78bd19df6c7cb72224cdec7ee07   \n",
       "36455  110f5cd40aa0ff4381f7abc3cabbc629f9794e66   \n",
       "36456  3dfe29d041cefc6bf7640ae82e2512dba55d9a7d   \n",
       "\n",
       "                                           keyword_match  \n",
       "0      ['severe acute respiratory syndrome', 'glioma'...  \n",
       "1      ['pseudomonas aeruginosa', 'human metapneumovi...  \n",
       "2      ['notch', 'nr', 'falls', 'hepatitis b', 'hepat...  \n",
       "3      ['dengue', 'water', 'vesicular stomatitis viru...  \n",
       "4      ['yellow fever', 'apoptosis', 'nr', 'atopic de...  \n",
       "...                                                  ...  \n",
       "36452  ['nr', 'apoptosis', 'tiletamine', 'arginine', ...  \n",
       "36453  ['water', 'hepatitis e', 'serine', 'aved', 'et...  \n",
       "36454  ['water', 'ethanol', 'nr', 'pica', 'pain', 'bi...  \n",
       "36455  ['vaccinia', 'aved', 'ethylcellulose', 'pica',...  \n",
       "36456  ['water', 'aved', 'inositol', 'pica', 'parafor...  \n",
       "\n",
       "[36457 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataframe\n",
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tokanization and vectorization of keywords</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer for list comprehension stored as string\n",
    "def list_comprehension_str_tokenizer(list_comprehension_str):\n",
    "    # Generates a list of strings from a list comprehension in string format\n",
    "    # Example: String literal \"['word1','word2']\"  will be converted to list ['word1','word2']\n",
    "    return list_comprehension_str[1:-2].replace(\"\\'\",\"\").split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and check distribution of words\n",
    "l = np.array(list(map(lambda x: len(list_comprehension_str_tokenizer(x)), kw_df['keyword_match'])))\n",
    "print(\"# of documents with 0 keywords:\", sum(l==0))\n",
    "#Plot partial histogram\n",
    "plt.hist(l, bins = list(range(0,100,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer. More stop words can be added.\n",
    "kw_vectorizer = CountVectorizer(tokenizer=list_comprehension_str_tokenizer,\n",
    "                             stop_words=['tic','ether','pica','rigi','nr','thc','orf',\n",
    "                                         'elm','fits','aids','water','agar','aved',\n",
    "                                         '', 'at', 'g', 'i', 'th', 'v'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The texts variable is a list of strings. Get it either as a Dataframe column or as a list of strings.\n",
    "kw_vectorized = kw_vectorizer.fit_transform(tqdm(kw_df['keyword_match'])) # Use tqdm(texts) if you want to see the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sizes of vectorized data\n",
    "print(\"Type of vectorized data:\", type(kw_vectorized))\n",
    "print(\"Vectorized data (#documents, #features):\", kw_vectorized.shape)\n",
    "print(\"Vectorizer (#features):\", len(kw_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump vectorizer and vetorized data (OPTIONAL). Might save time next time. Just use pickle.load().\n",
    "pickle.dump(kw_vectorizer, open('3.lda_visualization_fulltext-keyword-vectorizer.pkl', \"wb\")) # Writing binary file\n",
    "pickle.dump(kw_vectorized, open('3.lda_visualization_fulltext-keyword-vectorized.pkl', \"wb\")) # Writing binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load vectorizer and vectorized data\n",
    "#kw_vectorizer = pickle.load(open('3.lda_visualization_fulltext-keyword-vectorizer.pkl', \"rb\"))\n",
    "#kw_vectorized = pickle.load(open('3.lda_visualization_fulltext-keyword-vectorized.pkl', \"rb\"))\n",
    "\n",
    "# Check whether all features are loaded\n",
    "#print(\"# Features:\", len(kw_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Most frequent keywords\n",
    "word_count = pd.DataFrame({'word': kw_vectorizer.get_feature_names(), 'count': np.asarray(kw_vectorized.sum(axis=0))[0]})\n",
    "word_count.sort_values('count', ascending=False).set_index('word')[:20].sort_values('count', ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Merge vectorized keywords with vectorized entities from abstracts (Obtained from 1.abstrac_entity_vectorization.ipynb)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vectorized data to data frame\n",
    "kw_vec_mat = kw_vectorized.todense()\n",
    "kw_vec_df = pd.DataFrame(kw_vec_mat, index=kw_df['paper_id'], columns=kw_vectorizer.get_feature_names())\n",
    "kw_vec_df = kw_vec_df.reset_index()\n",
    "print(\"DataFrame shape:\", kw_vec_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read vectorized entities from abstract and corresponding dataframe\n",
    "ab_vectorizer = pickle.load(open('1.abstrac_entity_vectorization_vectorizer.pkl', \"rb\"))\n",
    "ab_vectorized = pickle.load(open('1.abstrac_entity_vectorization_vectorized.pkl', \"rb\"))\n",
    "ab_df_full = pd.read_csv(\"1.abstrac_entity_vectorization_abstract-entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (36957, 790)\n"
     ]
    }
   ],
   "source": [
    "# Convert vectorized data to data frame\n",
    "ab_vec_mat = ab_vectorized.todense()\n",
    "ab_vec_df = pd.DataFrame(ab_vec_mat, index=ab_df_full['paper_id'], columns=ab_vectorizer.get_feature_names())\n",
    "ab_vec_df = ab_vec_df.reset_index()\n",
    "print(\"DataFrame shape:\", ab_vec_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rotavirus',\n",
       " 'adenovirus',\n",
       " 'immune',\n",
       " 'dengue',\n",
       " 'human',\n",
       " 'medical',\n",
       " 'paper_id',\n",
       " 'cough',\n",
       " 'transcription',\n",
       " 'air',\n",
       " 'rhinovirus',\n",
       " 'ifn',\n",
       " 'influenza',\n",
       " 'apoptosis',\n",
       " 'parainfluenza']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get common columns\n",
    "kw_cols = set(kw_vec_df.columns)\n",
    "ab_cols = set(ab_vec_df.columns)\n",
    "kw_ab_intersect_cols = kw_cols.intersection(ab_cols)\n",
    "list(kw_ab_intersect_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop common columns from keywords dataframe, except for paper_id\n",
    "# Manual input needed here. Copy the column names from the above cell and paste here. Remove paper_id.\n",
    "drop_cols = ['rotavirus',\n",
    " 'adenovirus',\n",
    " 'immune',\n",
    " 'dengue',\n",
    " 'human',\n",
    " 'medical',\n",
    " 'cough',\n",
    " 'transcription',\n",
    " 'air',\n",
    " 'rhinovirus',\n",
    " 'ifn',\n",
    " 'influenza',\n",
    " 'apoptosis',\n",
    " 'parainfluenza']\n",
    "\n",
    "kw_vec_df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "vec_df = kw_vec_df.merge(ab_vec_df, how=\"left\", on=\"paper_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36457, 5837)\n"
     ]
    }
   ],
   "source": [
    "print(vec_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all texts in the list format required by Gensim.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of words for each document\n",
    "def getVectorized(catch_array):\n",
    "    columnanmes = vec_df.columns[2:]\n",
    "    catch_array = catch_array[2:]\n",
    "    new_array = []\n",
    "    for idx, val in enumerate(catch_array):\n",
    "        if catch_array[idx]>0:\n",
    "            #new_array.append(catch_array[idx]*[columnanmes[idx]])\n",
    "            new_array.append(catch_array[idx]*[columnanmes[idx]])\n",
    "    return [item for sublist in new_array for item in sublist if item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df['vectorized_array'] = vec_df.apply(lambda x : getVectorized(x.values), axis=1)\n",
    "# Confirm that the conversion worked\n",
    "#print(vec_df['vectorized_array'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all lists of words as a single list of lists\n",
    "texts = list(vec_df['vectorized_array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(5835 unique tokens: ['acne', 'alcohol', 'alcohol dependence', 'breast cancer', 'cell cycle']...)\n",
      "Length of corpus: 36457\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary and corpus for Gensim LDA model\n",
    "np.random.seed(42)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(dictionary)\n",
    "print(\"Length of corpus:\", len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic modeling using LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_gridsearch(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    # Function to perform grid search on LDA model parameters (currently for number of topics)\n",
    "    # Returns coherence score of tested models\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit+step, step):\n",
    "        print(\"Building model for\", num_topics, \"topics.\")\n",
    "        #Use following for standard gensim model\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=dictionary,\n",
    "                                                num_topics=num_topics, \n",
    "                                                random_state=42,\n",
    "                                                update_every=1,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                minimum_probability=0,\n",
    "                                                per_word_topics=True)\n",
    "        #Use following for mallet model (if installed)\n",
    "        #model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search LDA model parameters (currently, number of topics)\n",
    "start=2; limit=30; step=2;\n",
    "model_list, coherence_values = lda_gridsearch(dictionary=dictionary, corpus=corpus, texts=texts,\n",
    "                                                    start=start, limit=limit, step=step) # Inclusive of start and limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coherence scores\n",
    "x = range(start, limit+step, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of topics based on grid search results\n",
    "ntopics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model. You can try to give more number of passes.\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=ntopics, \n",
    "                                            random_state=42,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=50,\n",
    "                                            alpha='auto',\n",
    "                                            minimum_probability=0,\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model / Load model\n",
    "pickle.dump(lda_model, open('3.lda_visualization_nTopics'+str(lda_model.num_topics)+'.pkl', \"wb\")) # Writing binary file\n",
    "#lda_model = pickle.load(open('3.lda_visualization_nTopics'+str(lda_model.num_topics)+'.pkl', \"wb\")) # Writing binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.538123283423558\n",
      "\n",
      "Coherence Score:  0.5934183841010918\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.074*\"cell\" + 0.056*\"infection\" + 0.041*\"response\" + 0.027*\"immune\" + '\n",
      "  '0.023*\"mouse\" + 0.021*\"expression\" + 0.018*\"effect\" + 0.018*\"symptom\" + '\n",
      "  '0.017*\"treatment\" + 0.016*\"increase\"'),\n",
      " (1,\n",
      "  '0.058*\"vaccine\" + 0.050*\"day\" + 0.050*\"antibody\" + 0.042*\"strain\" + '\n",
      "  '0.024*\"serum\" + 0.023*\"pedv\" + 0.021*\"animal\" + 0.018*\"porcine\" + '\n",
      "  '0.018*\"pig\" + 0.018*\"group\"'),\n",
      " (2,\n",
      "  '0.049*\"protein\" + 0.047*\"virus\" + 0.027*\"cell\" + 0.026*\"viral\" + '\n",
      "  '0.024*\"rna\" + 0.023*\"gene\" + 0.020*\"host\" + 0.016*\"sequence\" + '\n",
      "  '0.013*\"replication\" + 0.013*\"human\"'),\n",
      " (3,\n",
      "  '0.034*\"drug\" + 0.023*\"hepatitis c\" + 0.021*\"domain\" + 0.017*\"ethanol\" + '\n",
      "  '0.016*\"hepatitis c virus\" + 0.015*\"glucose\" + 0.015*\"calcium\" + '\n",
      "  '0.015*\"compound\" + 0.014*\"rosin\" + 0.014*\"serine\"'),\n",
      " (4,\n",
      "  '0.083*\"disease\" + 0.063*\"health\" + 0.034*\"population\" + 0.033*\"infectious\" '\n",
      "  '+ 0.029*\"public\" + 0.028*\"country\" + 0.026*\"human\" + 0.023*\"pandemic\" + '\n",
      "  '0.022*\"risk\" + 0.020*\"global\"'),\n",
      " (5,\n",
      "  '0.045*\"model\" + 0.044*\"covid\" + 0.042*\"19\" + 0.030*\"study\" + 0.030*\"datum\" '\n",
      "  '+ 0.023*\"analysis\" + 0.020*\"epidemic\" + 0.018*\"method\" + 0.018*\"level\" + '\n",
      "  '0.017*\"preprint\"'),\n",
      " (6,\n",
      "  '0.019*\"severe acute respiratory syndrome\" + 0.017*\"pain\" + '\n",
      "  '0.011*\"tuberculosis\" + 0.011*\"oxygen\" + 0.009*\"measles\" + '\n",
      "  '0.009*\"respiratory syncytial virus\" + 0.008*\"staphylococcus aureus\" + '\n",
      "  '0.008*\"respiratory distress\" + 0.007*\"rash\" + 0.007*\"wine\"'),\n",
      " (7,\n",
      "  '0.071*\"virus\" + 0.042*\"infection\" + 0.032*\"respiratory\" + 0.028*\"influenza\" '\n",
      "  '+ 0.027*\"viral\" + 0.023*\"positive\" + 0.023*\"pcr\" + 0.019*\"sample\" + '\n",
      "  '0.017*\"study\" + 0.017*\"human\"'),\n",
      " (8,\n",
      "  '0.064*\"sars\" + 0.061*\"patient\" + 0.059*\"cov\" + 0.039*\"case\" + '\n",
      "  '0.022*\"infection\" + 0.020*\"severe\" + 0.020*\"coronavirus\" + '\n",
      "  '0.020*\"transmission\" + 0.019*\"respiratory\" + 0.015*\"acute\"'),\n",
      " (9,\n",
      "  '0.079*\"assay\" + 0.056*\"detection\" + 0.050*\"test\" + 0.042*\"diagnostic\" + '\n",
      "  '0.041*\"sensitivity\" + 0.037*\"sample\" + 0.035*\"specificity\" + 0.028*\"dna\" + '\n",
      "  '0.027*\"testing\" + 0.024*\"cat\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the topics\n",
    "# NOTE: A human understable name needs to be created for each topic.\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to print topics\n",
    "# Print only two topics and represent by top 6 words\n",
    "#pprint(lda_model.print_topics(num_topics=2, num_words=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Visualize the topics. This can take too long for large models.\n",
    "#pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "#vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save doc-topic distribution\n",
    "doc_topic_lda = lda_model[corpus]\n",
    "doc_topic_df = pd.DataFrame(doc_topic_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36457, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(0, 0.01544548), (1, 0.010459503), (2, 0.0200...</td>\n",
       "      <td>[(0, [3]), (1, [6, 3]), (2, [6]), (3, [3]), (4...</td>\n",
       "      <td>[(0, [(3, 0.9997795)]), (1, [(3, 0.3732544), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(0, 0.0666787), (1, 0.0041270824), (2, 0.0094...</td>\n",
       "      <td>[(6, [7, 4, 6, 3, 2]), (22, [8, 0]), (23, [7, ...</td>\n",
       "      <td>[(6, [(2, 0.01743876), (3, 0.086157136), (4, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(0, 0.056981664), (1, 0.0041263695), (2, 0.31...</td>\n",
       "      <td>[(7, [4, 6]), (25, [5, 9, 2]), (33, [4, 8, 0])...</td>\n",
       "      <td>[(7, [(4, 0.7389295), (6, 0.2608259)]), (25, [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(0, 0.03264456), (1, 0.0055407207), (2, 0.713...</td>\n",
       "      <td>[(25, [5, 2]), (54, [6, 7]), (108, [0]), (109,...</td>\n",
       "      <td>[(25, [(2, 0.29172263), (5, 0.7080283)]), (54,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(0, 0.2987733), (1, 0.062128287), (2, 0.05205...</td>\n",
       "      <td>[(10, [6, 3, 7, 2]), (14, [6, 3, 0]), (33, [4,...</td>\n",
       "      <td>[(10, [(2, 0.018720211), (3, 0.24642244), (6, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [(0, 0.01544548), (1, 0.010459503), (2, 0.0200...   \n",
       "1  [(0, 0.0666787), (1, 0.0041270824), (2, 0.0094...   \n",
       "2  [(0, 0.056981664), (1, 0.0041263695), (2, 0.31...   \n",
       "3  [(0, 0.03264456), (1, 0.0055407207), (2, 0.713...   \n",
       "4  [(0, 0.2987733), (1, 0.062128287), (2, 0.05205...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [(0, [3]), (1, [6, 3]), (2, [6]), (3, [3]), (4...   \n",
       "1  [(6, [7, 4, 6, 3, 2]), (22, [8, 0]), (23, [7, ...   \n",
       "2  [(7, [4, 6]), (25, [5, 9, 2]), (33, [4, 8, 0])...   \n",
       "3  [(25, [5, 2]), (54, [6, 7]), (108, [0]), (109,...   \n",
       "4  [(10, [6, 3, 7, 2]), (14, [6, 3, 0]), (33, [4,...   \n",
       "\n",
       "                                                   2  \n",
       "0  [(0, [(3, 0.9997795)]), (1, [(3, 0.3732544), (...  \n",
       "1  [(6, [(2, 0.01743876), (3, 0.086157136), (4, 0...  \n",
       "2  [(7, [(4, 0.7389295), (6, 0.2608259)]), (25, [...  \n",
       "3  [(25, [(2, 0.29172263), (5, 0.7080283)]), (54,...  \n",
       "4  [(10, [(2, 0.018720211), (3, 0.24642244), (6, ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check doc-topic distribution\n",
    "print(doc_topic_df.shape)\n",
    "doc_topic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot topics for selected document</h3>\n",
    "<b>Bubble chart is as follows:\n",
    "<ul>\n",
    "    <li>X-axis shows top N topics for a chosen document.</li>\n",
    "    <li>Y-axis denotes how much importance of the topic in the document. (Higher the y-value, more the importance of the topic in this document.)</li>\n",
    "    <li>Radius of the bubble denotes in how many other documents this topic is important. The importance can be set using a threshold. (Larger the radius, higher chances of finding a similar document. Or, smaller the radius, more unique is the document.)</li>\n",
    "</ul>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 327, 1: 67, 2: 3110, 3: 266, 4: 224, 5: 379, 6: 5025, 7: 1147, 8: 703, 9: 7}\n"
     ]
    }
   ],
   "source": [
    "# Get number of documents for all topics beyond a selected threshold.\n",
    "# This number will be used to assign radius of bubble.\n",
    "topic_doc_cnt_threshod = 0.5\n",
    "topic_doc_cnt = {i:0 for i in range(0,lda_model.num_topics)}\n",
    "for topicid in range(0,lda_model.num_topics):\n",
    "    for docid in doc_topic_df.index:\n",
    "        for item in doc_topic_df.iloc[docid][0]:\n",
    "            if item[0] == topicid and item[1]>topic_doc_cnt_threshod:\n",
    "                topic_doc_cnt[topicid] += 1\n",
    "print(topic_doc_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"97bb050a-c963-43f4-b2f2-4a0afbb8265c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"97bb050a-c963-43f4-b2f2-4a0afbb8265c\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '97bb050a-c963-43f4-b2f2-4a0afbb8265c',\n",
       "                        [{\"marker\": {\"size\": [9.81, 2.01, 93.3, 7.9799999999999995, 6.72, 11.37, 150.75, 34.41, 21.09, 0.21]}, \"mode\": \"markers\", \"type\": \"scatter\", \"x\": [\"Topic0\", \"Topic1\", \"Topic2\", \"Topic3\", \"Topic4\", \"Topic5\", \"Topic6\", \"Topic7\", \"Topic8\", \"Topic9\"], \"y\": [0.05698166415095329, 0.00412636948749423, 0.31044846773147583, 0.07658695429563522, 0.09992168843746185, 0.30440953373908997, 0.03412538021802902, 0.006619337014853954, 0.07380497455596924, 0.03297560662031174]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('97bb050a-c963-43f4-b2f2-4a0afbb8265c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected document id: 2\n"
     ]
    }
   ],
   "source": [
    "# Choose docment id to view\n",
    "docid = 2\n",
    "\n",
    "doc_topic_weight = {item[0]:item[1] for item in doc_topic_df.iloc[docid][0]}\n",
    "for topicid in range(0,lda_model.num_topics):\n",
    "    if topicid not in doc_topic_weight:\n",
    "        doc_topic_weight[topicid] = 0.0\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    #x=[1, 3.2, 5.4, 7.6, 9.8, 12.5],\n",
    "    x=[\"Topic\"+str(i) for i in range(0,lda_model.num_topics)],\n",
    "    y=[doc_topic_weight[i] for i in sorted(doc_topic_weight.keys())],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        #color=[120, 125, 130, 135, 140, 145],\n",
    "        size=[0.03*topic_doc_cnt[i] for i in sorted(topic_doc_cnt.keys())],\n",
    "        #showscale=False\n",
    "        )\n",
    ")])\n",
    "fig.show()\n",
    "print(\"Selected document id:\", docid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
